// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
// SPDX-License-Identifier: Apache-2.0

/**
 * This file was generated with the `generate-red-worker-code.js` script.
 */

/**
 * Redundant audio worker code string.
 */
// eslint-disable-next-line
const RedundantAudioEncoderWorkerCode = "class RedundantAudioEncoder {\r\n    constructor() {\r\n        // Each payload must be less than 1024 bytes to fit the 10 bit block length\r\n        this.maxRedPacketSizeBytes = 1 << 10;\r\n        // Limit payload to 1000 bytes to handle small MTU. 1000 is chosen because in Chromium-based browsers, writing audio\r\n        // payloads larger than 1000 bytes using the WebRTC Insertable Streams API (which is used to enable dynamic audio\r\n        // redundancy) will cause an error to be thrown and cause audio flow to permanently stop. See\r\n        // https://crbug.com/1248479.\r\n        this.maxAudioPayloadSizeBytes = 1000;\r\n        // Each payload can encode a timestamp delta of 14 bits\r\n        this.maxRedTimestampOffset = 1 << 14;\r\n        // 4 byte RED header\r\n        this.redHeaderSizeBytes = 4;\r\n        // reduced size for last RED header\r\n        this.redLastHeaderSizeBytes = 1;\r\n        // P-Time for Opus 20 msec packets\r\n        // We do not support other p-times or clock rates\r\n        this.redPacketizationTime = 960;\r\n        // distance between redundant payloads, Opus FEC handles a distance of 1\r\n        // TODO(https://issues.amazon.com/issues/ChimeSDKAudio-55):\r\n        // Consider making this dynamic\r\n        this.redPacketDistance = 2;\r\n        // maximum number of redundant payloads per RTP packet\r\n        this.maxRedEncodings = 2;\r\n        // Maximum number of encodings that can be recovered with a single RED packet, assuming the primary and redundant\r\n        // payloads have FEC.\r\n        this.redMaxRecoveryDistance = this.redPacketDistance * this.maxRedEncodings + 1;\r\n        // maximum history of prior payloads to keep\r\n        // generally we will expire old entries based on timestamp\r\n        // this limit is in place just to make sure the history does not\r\n        // grow too large in the case of erroneous timestamp inputs\r\n        this.maxEncodingHistorySize = 10;\r\n        // Current number of encodings we want to send\r\n        // to the remote end. This will be dynamically\r\n        // updated through the setNumEncodingsFromPacketloss API\r\n        this.numRedundantEncodings = 0;\r\n        // Used to enable or disable redundancy\r\n        // in response to very high packet loss events\r\n        this.redundancyEnabled = true;\r\n        // Loss stats are reported to the main thread every 5 seconds.\r\n        // Since timestamp differences between 2 consecutive packets\r\n        // give us the number of samples in each channel, 1 second\r\n        // is equivalent to 48000 samples:\r\n        // P-time * (1000ms/1s)\r\n        // = (960 samples/20ms) * (1000ms/1s)\r\n        // = 48000 samples/s\r\n        this.lossReportInterval = 48000 * 5;\r\n        // Maximum distance of a packet from the most recent packet timestamp\r\n        // that we will consider for recovery.\r\n        this.maxOutOfOrderPacketDistance = 16;\r\n        /**\r\n         * Below are Opus helper methods and constants.\r\n         */\r\n        this.OPUS_BAD_ARG = -1;\r\n        this.OPUS_INVALID_PACKET = -4;\r\n        // Max number of Opus frames in an Opus packet is 48 (https://www.rfc-editor.org/rfc/rfc6716#section-3.2.5).\r\n        this.OPUS_MAX_OPUS_FRAMES = 48;\r\n        // Max number of bytes that any individual Opus frame can have.\r\n        this.OPUS_MAX_FRAME_SIZE_BYTES = 1275;\r\n        this.encodingHistory = new Array();\r\n        this.opusPayloadType = 0;\r\n        this.redPayloadType = 0;\r\n        this.initializePacketLogs();\r\n    }\r\n    /**\r\n     * Creates an instance of RedundantAudioEncoder and sets up callbacks.\r\n     */\r\n    static initializeWorker() {\r\n        RedundantAudioEncoder.log('Initializing RedundantAudioEncoder');\r\n        const encoder = new RedundantAudioEncoder();\r\n        // RED encoding is done using WebRTC Encoded Transform\r\n        // https://github.com/w3c/webrtc-encoded-transform/blob/main/explainer.md\r\n        // Check the DedicatedWorkerGlobalScope for existence of\r\n        // RTCRtpScriptTransformer interface. If exists, then\r\n        // RTCRtpScriptTransform is supported by this browser.\r\n        // @ts-ignore\r\n        if (self.RTCRtpScriptTransformer) {\r\n            // @ts-ignore\r\n            self.onrtctransform = (event) => {\r\n                if (event.transformer.options.type === 'SenderTransform') {\r\n                    encoder.setupSenderTransform(event.transformer.readable, event.transformer.writable);\r\n                }\r\n                else if (event.transformer.options.type === 'ReceiverTransform') {\r\n                    encoder.setupReceiverTransform(event.transformer.readable, event.transformer.writable);\r\n                }\r\n                else if (event.transformer.options.type === 'PassthroughTransform') {\r\n                    encoder.setupPassthroughTransform(event.transformer.readable, event.transformer.writable);\r\n                }\r\n            };\r\n        }\r\n        self.onmessage = (event) => {\r\n            if (event.data.msgType === 'StartRedWorker') {\r\n                encoder.setupSenderTransform(event.data.send.readable, event.data.send.writable);\r\n                encoder.setupReceiverTransform(event.data.receive.readable, event.data.receive.writable);\r\n            }\r\n            else if (event.data.msgType === 'PassthroughTransform') {\r\n                encoder.setupPassthroughTransform(event.data.send.readable, event.data.send.writable);\r\n                encoder.setupPassthroughTransform(event.data.receive.readable, event.data.receive.writable);\r\n            }\r\n            else if (event.data.msgType === 'RedPayloadType') {\r\n                encoder.setRedPayloadType(event.data.payloadType);\r\n            }\r\n            else if (event.data.msgType === 'OpusPayloadType') {\r\n                encoder.setOpusPayloadType(event.data.payloadType);\r\n            }\r\n            else if (event.data.msgType === 'UpdateNumRedundantEncodings') {\r\n                encoder.setNumRedundantEncodings(event.data.numRedundantEncodings);\r\n            }\r\n            else if (event.data.msgType === 'Enable') {\r\n                encoder.setRedundancyEnabled(true);\r\n            }\r\n            else if (event.data.msgType === 'Disable') {\r\n                encoder.setRedundancyEnabled(false);\r\n            }\r\n        };\r\n    }\r\n    /**\r\n     * Post logs to the main thread\r\n     */\r\n    static log(msg) {\r\n        if (RedundantAudioEncoder.shouldLog) {\r\n            // @ts-ignore\r\n            self.postMessage({\r\n                type: 'REDWorkerLog',\r\n                log: `[AudioRed] ${msg}`,\r\n            });\r\n        }\r\n    }\r\n    /**\r\n     * Returns the number of encodings based on packetLoss value. This is used by `DefaultTransceiverController` to\r\n     * determine when to alert the encoder to update the number of encodings. It also determines if we need to\r\n     * turn off red in cases of very high packet loss to avoid congestion collapse.\r\n     */\r\n    static getNumRedundantEncodingsForPacketLoss(packetLoss) {\r\n        let recommendedRedundantEncodings = 0;\r\n        let shouldTurnOffRed = false;\r\n        if (packetLoss <= 8) {\r\n            recommendedRedundantEncodings = 0;\r\n        }\r\n        else if (packetLoss <= 18) {\r\n            recommendedRedundantEncodings = 1;\r\n        }\r\n        else if (packetLoss <= 75) {\r\n            recommendedRedundantEncodings = 2;\r\n        }\r\n        else {\r\n            recommendedRedundantEncodings = 0;\r\n            shouldTurnOffRed = true;\r\n        }\r\n        return [recommendedRedundantEncodings, shouldTurnOffRed];\r\n    }\r\n    /**\r\n     * Sets up a passthrough (no-op) transform for the given streams.\r\n     */\r\n    setupPassthroughTransform(readable, writable) {\r\n        RedundantAudioEncoder.log('Setting up passthrough transform');\r\n        readable.pipeTo(writable);\r\n    }\r\n    /**\r\n     * Sets up the transform stream and pipes the outgoing encoded audio frames through the transform function.\r\n     */\r\n    setupSenderTransform(readable, writable) {\r\n        RedundantAudioEncoder.log('Setting up sender RED transform');\r\n        const transformStream = new TransformStream({\r\n            transform: this.senderTransform.bind(this),\r\n        });\r\n        readable.pipeThrough(transformStream).pipeTo(writable);\r\n        return;\r\n    }\r\n    /**\r\n     * Sets up the transform stream and pipes the received encoded audio frames through the transform function.\r\n     */\r\n    setupReceiverTransform(readable, writable) {\r\n        RedundantAudioEncoder.log('Setting up receiver RED transform');\r\n        const transformStream = new TransformStream({\r\n            transform: this.receivePacketLogTransform.bind(this),\r\n        });\r\n        readable.pipeThrough(transformStream).pipeTo(writable);\r\n        return;\r\n    }\r\n    /**\r\n     * Set the RED payload type ideally obtained from local offer.\r\n     */\r\n    setRedPayloadType(payloadType) {\r\n        this.redPayloadType = payloadType;\r\n        RedundantAudioEncoder.log(`red payload type set to ${this.redPayloadType}`);\r\n    }\r\n    /**\r\n     * Set the opus payload type ideally obtained from local offer.\r\n     */\r\n    setOpusPayloadType(payloadType) {\r\n        this.opusPayloadType = payloadType;\r\n        RedundantAudioEncoder.log(`opus payload type set to ${this.opusPayloadType}`);\r\n    }\r\n    /**\r\n     * Set the number of redundant encodings\r\n     */\r\n    setNumRedundantEncodings(numRedundantEncodings) {\r\n        this.numRedundantEncodings = numRedundantEncodings;\r\n        if (this.numRedundantEncodings > this.maxRedEncodings) {\r\n            this.numRedundantEncodings = this.maxRedEncodings;\r\n        }\r\n        RedundantAudioEncoder.log(`Updated numRedundantEncodings to ${this.numRedundantEncodings}`);\r\n    }\r\n    /**\r\n     * Enable or disable redundancy in response to\r\n     * high packet loss event.\r\n     */\r\n    setRedundancyEnabled(enabled) {\r\n        this.redundancyEnabled = enabled;\r\n        RedundantAudioEncoder.log(`redundancy ${this.redundancyEnabled ? 'enabled' : 'disabled'}`);\r\n    }\r\n    /**\r\n     * Helper function to only enqueue audio frames if they do not exceed the audio payload byte limit imposed by\r\n     * Chromium-based browsers. Chromium will throw an error (https://crbug.com/1248479) if an audio payload larger than\r\n     * 1000 bytes is enqueued. Any controller that attempts to enqueue an audio payload larger than 1000 bytes will\r\n     * encounter this error and will permanently stop sending or receiving audio.\r\n     */\r\n    enqueueAudioFrameIfPayloadSizeIsValid(\r\n    // @ts-ignore\r\n    frame, controller) {\r\n        if (frame.data.byteLength > this.maxAudioPayloadSizeBytes)\r\n            return;\r\n        controller.enqueue(frame);\r\n    }\r\n    /**\r\n     * Receives encoded frames and modifies as needed before sending to transport.\r\n     */\r\n    senderTransform(\r\n    // @ts-ignore\r\n    frame, controller) {\r\n        const frameMetadata = frame.getMetadata();\r\n        // @ts-ignore\r\n        if (frameMetadata.payloadType !== this.redPayloadType) {\r\n            this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n            return;\r\n        }\r\n        const primaryPayloadBuffer = this.getPrimaryPayload(frame.timestamp, frame.data);\r\n        if (!primaryPayloadBuffer) {\r\n            this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n            return;\r\n        }\r\n        const encodedBuffer = this.encode(frame.timestamp, primaryPayloadBuffer);\r\n        /* istanbul ignore next */\r\n        if (!encodedBuffer) {\r\n            this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n            return;\r\n        }\r\n        frame.data = encodedBuffer;\r\n        this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n        return;\r\n    }\r\n    /**\r\n     * Get the primary payload from encoding\r\n     */\r\n    getPrimaryPayload(primaryTimestamp, frame) {\r\n        const encodings = this.splitEncodings(primaryTimestamp, frame);\r\n        if (!encodings || encodings.length < 1)\r\n            return null;\r\n        return encodings[encodings.length - 1].payload;\r\n    }\r\n    /**\r\n     * Split up the encoding received into primary and redundant encodings\r\n     * These will be ordered oldest to newest which is the same ordering\r\n     * in the RTP red payload.\r\n     */\r\n    splitEncodings(primaryTimestamp, frame, getFecInfo = false, primarySequenceNumber = undefined) {\r\n        // process RED headers (according to RFC 2198)\r\n        //   0                   1                   2                   3\r\n        //   0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\r\n        //  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\r\n        //  |F|   block PT  |  timestamp offset         |   block length    |\r\n        //  +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\r\n        //\r\n        // last header\r\n        //   0 1 2 3 4 5 6 7\r\n        //  +-+-+-+-+-+-+-+-+\r\n        //  |0|   Block PT  |\r\n        //  +-+-+-+-+-+-+-+-+\r\n        const payload = new DataView(frame);\r\n        let payloadSizeBytes = payload.byteLength;\r\n        let totalPayloadSizeBytes = 0;\r\n        let totalHeaderSizeBytes = 0;\r\n        let primaryPayloadSizeBytes = 0;\r\n        let payloadOffset = 0;\r\n        let gotLastBlock = false;\r\n        const encodings = new Array();\r\n        const redundantEncodingBlockLengths = new Array();\r\n        const redundantEncodingTimestamps = new Array();\r\n        while (payloadSizeBytes > 0) {\r\n            gotLastBlock = (payload.getUint8(payloadOffset) & 0x80) === 0;\r\n            if (gotLastBlock) {\r\n                // Bits 1 through 7 are payload type\r\n                const payloadType = payload.getUint8(payloadOffset) & 0x7f;\r\n                // Unexpected payload type. This is a bad packet.\r\n                if (payloadType !== this.opusPayloadType) {\r\n                    return null;\r\n                }\r\n                totalPayloadSizeBytes += this.redLastHeaderSizeBytes;\r\n                totalHeaderSizeBytes += this.redLastHeaderSizeBytes;\r\n                // Accumulated block lengths are equal to or larger than the buffer, which means there is no primary block. This\r\n                // is a bad packet.\r\n                if (totalPayloadSizeBytes >= payload.byteLength) {\r\n                    return null;\r\n                }\r\n                primaryPayloadSizeBytes = payload.byteLength - totalPayloadSizeBytes;\r\n                break;\r\n            }\r\n            else {\r\n                if (payloadSizeBytes < this.redHeaderSizeBytes) {\r\n                    return null;\r\n                }\r\n                // Bits 22 through 31 are payload length\r\n                const blockLength = ((payload.getUint8(payloadOffset + 2) & 0x03) << 8) + payload.getUint8(payloadOffset + 3);\r\n                redundantEncodingBlockLengths.push(blockLength);\r\n                const timestampOffset = payload.getUint16(payloadOffset + 1) >> 2;\r\n                const timestamp = primaryTimestamp - timestampOffset;\r\n                redundantEncodingTimestamps.push(timestamp);\r\n                totalPayloadSizeBytes += blockLength + this.redHeaderSizeBytes;\r\n                totalHeaderSizeBytes += this.redHeaderSizeBytes;\r\n                payloadOffset += this.redHeaderSizeBytes;\r\n                payloadSizeBytes -= this.redHeaderSizeBytes;\r\n            }\r\n        }\r\n        // The last block was never found. The packet we received\r\n        // does not have a good RED payload.\r\n        if (!gotLastBlock) {\r\n            // Note that sequence numbers only exist for\r\n            // incoming audio frames.\r\n            if (primarySequenceNumber !== undefined) {\r\n                // This could be a possible padding packet used\r\n                // for BWE with a good sequence number.\r\n                // Create a dummy encoding to make sure loss values\r\n                // are calculated correctly by consuming sequence number.\r\n                // Note that for the receive side, we process packets only\r\n                // for loss/recovery calculations and forward the original\r\n                // packet without changing it even in the error case.\r\n                encodings.push({\r\n                    payload: frame,\r\n                    isRedundant: false,\r\n                    seq: primarySequenceNumber,\r\n                });\r\n                return encodings;\r\n            }\r\n            // This is a bad packet.\r\n            return null;\r\n        }\r\n        let redundantPayloadOffset = totalHeaderSizeBytes;\r\n        for (let i = 0; i < redundantEncodingTimestamps.length; i++) {\r\n            const redundantPayloadBuffer = new ArrayBuffer(redundantEncodingBlockLengths[i]);\r\n            const redundantPayloadArray = new Uint8Array(redundantPayloadBuffer);\r\n            redundantPayloadArray.set(new Uint8Array(payload.buffer, redundantPayloadOffset, redundantEncodingBlockLengths[i]), 0);\r\n            const encoding = {\r\n                timestamp: redundantEncodingTimestamps[i],\r\n                payload: redundantPayloadBuffer,\r\n                isRedundant: true,\r\n            };\r\n            if (getFecInfo) {\r\n                encoding.hasFec = this.opusPacketHasFec(new DataView(redundantPayloadBuffer), redundantPayloadBuffer.byteLength);\r\n            }\r\n            encodings.push(encoding);\r\n            redundantPayloadOffset += redundantEncodingBlockLengths[i];\r\n        }\r\n        const primaryPayloadOffset = payload.byteLength - primaryPayloadSizeBytes;\r\n        const primaryPayloadBuffer = new ArrayBuffer(primaryPayloadSizeBytes);\r\n        const primaryArray = new Uint8Array(primaryPayloadBuffer);\r\n        primaryArray.set(new Uint8Array(payload.buffer, primaryPayloadOffset, primaryPayloadSizeBytes), 0);\r\n        const encoding = {\r\n            timestamp: primaryTimestamp,\r\n            payload: primaryPayloadBuffer,\r\n            isRedundant: false,\r\n            seq: primarySequenceNumber,\r\n        };\r\n        if (getFecInfo) {\r\n            encoding.hasFec = this.opusPacketHasFec(new DataView(primaryPayloadBuffer), primaryPayloadBuffer.byteLength);\r\n        }\r\n        encodings.push(encoding);\r\n        return encodings;\r\n    }\r\n    /**\r\n     * Create a new encoding with current primary payload and the older payloads of choice.\r\n     */\r\n    encode(primaryTimestamp, primaryPayload) {\r\n        const primaryPayloadSize = primaryPayload.byteLength;\r\n        // Payload size needs to be valid.\r\n        if (primaryPayloadSize === 0 ||\r\n            primaryPayloadSize >= this.maxRedPacketSizeBytes ||\r\n            primaryPayloadSize >= this.maxAudioPayloadSizeBytes) {\r\n            return null;\r\n        }\r\n        const numRedundantEncodings = this.numRedundantEncodings;\r\n        let headerSizeBytes = this.redLastHeaderSizeBytes;\r\n        let payloadSizeBytes = primaryPayloadSize;\r\n        let bytesAvailable = this.maxAudioPayloadSizeBytes - primaryPayloadSize - headerSizeBytes;\r\n        const redundantEncodingTimestamps = new Array();\r\n        const redundantEncodingPayloads = new Array();\r\n        // If redundancy is disabled then only send the primary payload\r\n        if (this.redundancyEnabled) {\r\n            // Determine how much redundancy we can fit into our packet\r\n            let redundantTimestamp = this.uint32WrapAround(primaryTimestamp - this.redPacketizationTime * this.redPacketDistance);\r\n            for (let i = 0; i < numRedundantEncodings; i++) {\r\n                // Do not add redundant encodings that are beyond the maximum timestamp offset.\r\n                if (this.uint32WrapAround(primaryTimestamp - redundantTimestamp) >= this.maxRedTimestampOffset) {\r\n                    break;\r\n                }\r\n                let findTimestamp = redundantTimestamp;\r\n                let encoding = this.encodingHistory.find(e => e.timestamp === findTimestamp);\r\n                if (!encoding) {\r\n                    // If not found or not important then look for the previous packet.\r\n                    // The current packet may have included FEC for the previous, so just\r\n                    // use the previous packet instead provided that it has voice activity.\r\n                    findTimestamp = this.uint32WrapAround(redundantTimestamp - this.redPacketizationTime);\r\n                    encoding = this.encodingHistory.find(e => e.timestamp === findTimestamp);\r\n                }\r\n                if (encoding) {\r\n                    const redundantEncodingSizeBytes = encoding.payload.byteLength;\r\n                    // Only add redundancy if there are enough bytes available.\r\n                    if (bytesAvailable < this.redHeaderSizeBytes + redundantEncodingSizeBytes)\r\n                        break;\r\n                    bytesAvailable -= this.redHeaderSizeBytes + redundantEncodingSizeBytes;\r\n                    headerSizeBytes += this.redHeaderSizeBytes;\r\n                    payloadSizeBytes += redundantEncodingSizeBytes;\r\n                    redundantEncodingTimestamps.unshift(encoding.timestamp);\r\n                    redundantEncodingPayloads.unshift(encoding.payload);\r\n                }\r\n                redundantTimestamp -= this.redPacketizationTime * this.redPacketDistance;\r\n                redundantTimestamp = this.uint32WrapAround(redundantTimestamp);\r\n            }\r\n        }\r\n        const redPayloadBuffer = new ArrayBuffer(headerSizeBytes + payloadSizeBytes);\r\n        const redPayloadView = new DataView(redPayloadBuffer);\r\n        // Add redundant encoding header(s) to new buffer\r\n        let redPayloadOffset = 0;\r\n        for (let i = 0; i < redundantEncodingTimestamps.length; i++) {\r\n            const timestampDelta = primaryTimestamp - redundantEncodingTimestamps[i];\r\n            redPayloadView.setUint8(redPayloadOffset, this.opusPayloadType | 0x80);\r\n            redPayloadView.setUint16(redPayloadOffset + 1, (timestampDelta << 2) | (redundantEncodingPayloads[i].byteLength >> 8));\r\n            redPayloadView.setUint8(redPayloadOffset + 3, redundantEncodingPayloads[i].byteLength & 0xff);\r\n            redPayloadOffset += this.redHeaderSizeBytes;\r\n        }\r\n        // Add primary encoding header to new buffer\r\n        redPayloadView.setUint8(redPayloadOffset, this.opusPayloadType);\r\n        redPayloadOffset += this.redLastHeaderSizeBytes;\r\n        // Add redundant payload(s) to new buffer\r\n        const redPayloadArray = new Uint8Array(redPayloadBuffer);\r\n        for (let i = 0; i < redundantEncodingPayloads.length; i++) {\r\n            redPayloadArray.set(new Uint8Array(redundantEncodingPayloads[i]), redPayloadOffset);\r\n            redPayloadOffset += redundantEncodingPayloads[i].byteLength;\r\n        }\r\n        // Add primary payload to new buffer\r\n        redPayloadArray.set(new Uint8Array(primaryPayload), redPayloadOffset);\r\n        redPayloadOffset += primaryPayload.byteLength;\r\n        /* istanbul ignore next */\r\n        // Sanity check that we got the expected total payload size.\r\n        if (redPayloadOffset !== headerSizeBytes + payloadSizeBytes)\r\n            return null;\r\n        this.updateEncodingHistory(primaryTimestamp, primaryPayload);\r\n        return redPayloadBuffer;\r\n    }\r\n    /**\r\n     * Update the encoding history with the latest primary encoding\r\n     */\r\n    updateEncodingHistory(primaryTimestamp, primaryPayload) {\r\n        // Remove encodings from the history if they are too old.\r\n        for (const encoding of this.encodingHistory) {\r\n            const maxTimestampDelta = this.redPacketizationTime * this.redMaxRecoveryDistance;\r\n            if (primaryTimestamp - encoding.timestamp >= maxTimestampDelta) {\r\n                this.encodingHistory.shift();\r\n            }\r\n            else {\r\n                break;\r\n            }\r\n        }\r\n        // Only add an encoding to the history if the encoding is deemed to be important. An encoding is important if it is\r\n        // a CELT-only packet or contains voice activity.\r\n        const packet = new DataView(primaryPayload);\r\n        if (this.opusPacketIsCeltOnly(packet) ||\r\n            this.opusPacketHasVoiceActivity(packet, packet.byteLength) > 0) {\r\n            // Check if adding an encoding will cause the length of the encoding history to exceed the maximum history size.\r\n            // This is not expected to happen but could occur if we get incorrect timestamps. We want to make sure our memory\r\n            // usage is bounded. In this case, just clear the history and start over from empty.\r\n            if (this.encodingHistory.length + 1 > this.maxEncodingHistorySize)\r\n                this.encodingHistory.length = 0;\r\n            this.encodingHistory.push({ timestamp: primaryTimestamp, payload: primaryPayload });\r\n        }\r\n    }\r\n    /**\r\n     * Initialize packet logs and metric values.\r\n     */\r\n    initializePacketLogs() {\r\n        // The extra space from the max RED recovery distance is to ensure that we do not incorrectly count recovery for\r\n        // packets that have already been received but are outside of the max out-of-order distance.\r\n        const packetLogSize = this.maxOutOfOrderPacketDistance + this.redMaxRecoveryDistance;\r\n        this.primaryPacketLog = {\r\n            window: new Array(packetLogSize),\r\n            index: 0,\r\n            windowSize: packetLogSize,\r\n        };\r\n        this.redRecoveryLog = {\r\n            window: new Array(packetLogSize),\r\n            index: 0,\r\n            windowSize: packetLogSize,\r\n        };\r\n        this.fecRecoveryLog = {\r\n            window: new Array(packetLogSize),\r\n            index: 0,\r\n            windowSize: packetLogSize,\r\n        };\r\n        this.totalAudioPacketsExpected = 0;\r\n        this.totalAudioPacketsLost = 0;\r\n        this.totalAudioPacketsRecoveredRed = 0;\r\n        this.totalAudioPacketsRecoveredFec = 0;\r\n    }\r\n    /**\r\n     * Receives encoded frames from the server\r\n     * and adds the timestamps to a packet log\r\n     * to calculate an approximate recovery metric.\r\n     */\r\n    receivePacketLogTransform(\r\n    // @ts-ignore\r\n    frame, controller) {\r\n        const frameMetadata = frame.getMetadata();\r\n        // @ts-ignore\r\n        if (frameMetadata.payloadType !== this.redPayloadType) {\r\n            this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n            return;\r\n        }\r\n        // @ts-ignore\r\n        const encodings = this.splitEncodings(frame.timestamp, frame.data, \r\n        /*getFecInfo*/ true, frameMetadata.sequenceNumber);\r\n        if (!encodings) {\r\n            this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n            return;\r\n        }\r\n        for (let i = encodings.length - 1; i >= 0; i--) {\r\n            if (this.updateLossStats(encodings[i])) {\r\n                this.updateRedStats(encodings[i]);\r\n                this.updateFecStats(encodings[i]);\r\n            }\r\n        }\r\n        this.maybeReportLossStats(frameMetadata.synchronizationSource, encodings[encodings.length - 1].timestamp);\r\n        this.enqueueAudioFrameIfPayloadSizeIsValid(frame, controller);\r\n    }\r\n    /**\r\n     * Adds a timestamp to the primary packet log.\r\n     * This also updates totalAudioPacketsLost and totalAudioPacketsExpected by looking\r\n     * at the difference between timestamps.\r\n     *\r\n     * @param encoding : The encoding to be analyzed\r\n     * @returns false if sequence number was greater than max out of order distance\r\n     *          true otherwise\r\n     */\r\n    updateLossStats(encoding) {\r\n        if (encoding.isRedundant)\r\n            return true;\r\n        const timestamp = encoding.timestamp;\r\n        const seq = encoding.seq;\r\n        if (this.totalAudioPacketsExpected === 0) {\r\n            this.totalAudioPacketsExpected = 1;\r\n            this.newestSequenceNumber = seq;\r\n            this.addTimestamp(this.primaryPacketLog, timestamp);\r\n            return true;\r\n        }\r\n        const diff = this.int16(seq - this.newestSequenceNumber);\r\n        if (diff < -this.maxOutOfOrderPacketDistance)\r\n            return false;\r\n        if (diff < 0) {\r\n            if (!this.hasTimestamp(this.primaryPacketLog, timestamp)) {\r\n                if (this.totalAudioPacketsLost > 0)\r\n                    this.totalAudioPacketsLost--;\r\n                this.addTimestamp(this.primaryPacketLog, timestamp);\r\n                this.removeFromRecoveryWindows(timestamp);\r\n            }\r\n        }\r\n        else if (diff > 1) {\r\n            this.totalAudioPacketsLost += diff - 1;\r\n        }\r\n        if (diff > 0) {\r\n            this.totalAudioPacketsExpected += diff;\r\n            this.newestSequenceNumber = encoding.seq;\r\n            this.addTimestamp(this.primaryPacketLog, timestamp);\r\n        }\r\n        return true;\r\n    }\r\n    /**\r\n     * Adds a timestamp to the red recovery log if it is not present in\r\n     * the primary packet log and if it's not too old.\r\n     *\r\n     * @param encoding : The encoding to be analyzed\r\n     */\r\n    updateRedStats(encoding) {\r\n        if (!encoding.isRedundant || this.totalAudioPacketsLost === 0)\r\n            return;\r\n        const timestamp = encoding.timestamp;\r\n        if (!this.hasTimestamp(this.primaryPacketLog, timestamp)) {\r\n            if (!this.hasTimestamp(this.redRecoveryLog, timestamp)) {\r\n                this.totalAudioPacketsRecoveredRed++;\r\n                this.addTimestamp(this.redRecoveryLog, timestamp);\r\n            }\r\n            if (this.removeTimestamp(this.fecRecoveryLog, timestamp)) {\r\n                /* istanbul ignore else */\r\n                if (this.totalAudioPacketsRecoveredFec > 0)\r\n                    this.totalAudioPacketsRecoveredFec--;\r\n            }\r\n        }\r\n    }\r\n    /**\r\n     * Adds a timestamp to the fec recovery log if it is not present in\r\n     * the primary packet log and red recovery log and if it is not too old.\r\n     *\r\n     * @param encoding : The encoding to be analyzed\r\n     */\r\n    updateFecStats(encoding) {\r\n        if (!encoding.hasFec || this.totalAudioPacketsLost === 0)\r\n            return;\r\n        const fecTimestamp = encoding.timestamp - this.redPacketizationTime;\r\n        if (this.hasTimestamp(this.primaryPacketLog, fecTimestamp) ||\r\n            this.hasTimestamp(this.redRecoveryLog, fecTimestamp) ||\r\n            this.hasTimestamp(this.fecRecoveryLog, fecTimestamp)) {\r\n            return;\r\n        }\r\n        this.totalAudioPacketsRecoveredFec++;\r\n        this.addTimestamp(this.fecRecoveryLog, fecTimestamp);\r\n    }\r\n    /**\r\n     * Reports loss metrics to DefaultTransceiverController\r\n     *\r\n     * @param timestamp : Timestamp of most recent primary packet\r\n     */\r\n    maybeReportLossStats(ssrc, timestamp) {\r\n        if (timestamp === undefined ||\r\n            timestamp - this.lastLossReportTimestamp < this.lossReportInterval)\r\n            return;\r\n        /* istanbul ignore next */\r\n        if (RedundantAudioEncoder.shouldReportStats) {\r\n            // @ts-ignore\r\n            self.postMessage({\r\n                type: 'RedundantAudioEncoderStats',\r\n                ssrc,\r\n                totalAudioPacketsLost: this.totalAudioPacketsLost,\r\n                totalAudioPacketsExpected: this.totalAudioPacketsExpected,\r\n                totalAudioPacketsRecoveredRed: this.totalAudioPacketsRecoveredRed,\r\n                totalAudioPacketsRecoveredFec: this.totalAudioPacketsRecoveredFec,\r\n            });\r\n        }\r\n        this.lastLossReportTimestamp = timestamp;\r\n    }\r\n    /**\r\n     * Adds a timestamp to a packet log\r\n     *\r\n     * @param packetLog : The packetlog to add the timestamp to\r\n     * @param timestamp : The timestamp that should be added\r\n     */\r\n    addTimestamp(packetLog, timestamp) {\r\n        if (timestamp === undefined) {\r\n            return;\r\n        }\r\n        packetLog.window[packetLog.index] = timestamp;\r\n        packetLog.index = (packetLog.index + 1) % packetLog.windowSize;\r\n    }\r\n    /**\r\n     * Checks if a timestamp is in a packetlog\r\n     *\r\n     * @param packetLog : The packetlog to search\r\n     * @param timestamp : The timestamp to search for\r\n     * @returns true if timestamp is present, false otherwise\r\n     */\r\n    hasTimestamp(packetLog, timestamp) {\r\n        const element = packetLog.window.find(t => t === timestamp);\r\n        return !!element;\r\n    }\r\n    /**\r\n     * Removes a timestamp from a packet log\r\n     *\r\n     * @param packetLog : The packetlog from which the timestamp should be removed\r\n     * @param timestamp : The timestamp to be removed\r\n     * @returns true if timestamp was present in the log and removed, false otherwise\r\n     */\r\n    removeTimestamp(packetLog, timestamp) {\r\n        const index = packetLog.window.indexOf(timestamp);\r\n        if (index >= 0) {\r\n            packetLog.window[index] = undefined;\r\n            return true;\r\n        }\r\n        return false;\r\n    }\r\n    /**\r\n     * Removes a timestamp from red and fec recovery windows.\r\n     *\r\n     * @param timestamp : The timestamp to be removed\r\n     */\r\n    removeFromRecoveryWindows(timestamp) {\r\n        let removed = this.removeTimestamp(this.redRecoveryLog, timestamp);\r\n        if (removed) {\r\n            if (this.totalAudioPacketsRecoveredRed > 0)\r\n                this.totalAudioPacketsRecoveredRed--;\r\n        }\r\n        removed = this.removeTimestamp(this.fecRecoveryLog, timestamp);\r\n        if (removed) {\r\n            if (this.totalAudioPacketsRecoveredFec > 0)\r\n                this.totalAudioPacketsRecoveredFec--;\r\n        }\r\n    }\r\n    /**\r\n     * Converts the supplied argument to 32-bit unsigned integer\r\n     */\r\n    uint32WrapAround(num) {\r\n        const mod = 4294967296; // 2^32\r\n        let res = num;\r\n        if (num >= mod) {\r\n            res = num - mod;\r\n        }\r\n        else if (num < 0) {\r\n            res = mod + num;\r\n        }\r\n        return res;\r\n    }\r\n    /**\r\n     * Converts the supplied argument to 16-bit signed integer\r\n     */\r\n    int16(num) {\r\n        return (num << 16) >> 16;\r\n    }\r\n    /**\r\n     * Determines if an Opus packet is in CELT-only mode.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @returns `true` if the packet is in CELT-only mode.\r\n     */\r\n    opusPacketIsCeltOnly(packet) {\r\n        // TOC byte format (https://www.rfc-editor.org/rfc/rfc6716#section-3.1):\r\n        //  0\r\n        //  0 1 2 3 4 5 6 7\r\n        // +-+-+-+-+-+-+-+-+\r\n        // | config  |s| c |\r\n        // +-+-+-+-+-+-+-+-+\r\n        // Since CELT-only packets are represented using configurations 16 to 31, the highest 'config' bit will always be 1\r\n        // for CELT-only packets.\r\n        return !!(packet.getUint8(0) & 0x80);\r\n    }\r\n    /**\r\n     * Gets the number of samples per frame from an Opus packet.\r\n     *\r\n     * @param packet Opus packet. This must contain at least one byte of data.\r\n     * @param sampleRateHz 32-bit integer sampling rate in Hz. This must be a multiple of 400 or inaccurate results will\r\n     *                     be returned.\r\n     * @returns Number of samples per frame.\r\n     */\r\n    opusPacketGetSamplesPerFrame(packet, sampleRateHz) {\r\n        // Sample rate must be a 32-bit integer.\r\n        sampleRateHz = Math.round(sampleRateHz);\r\n        sampleRateHz = Math.min(Math.max(sampleRateHz, -(Math.pow(2, 32))), Math.pow(2, 32) - 1);\r\n        // TOC byte format (https://www.rfc-editor.org/rfc/rfc6716#section-3.1):\r\n        //  0\r\n        //  0 1 2 3 4 5 6 7\r\n        // +-+-+-+-+-+-+-+-+\r\n        // | config  |s| c |\r\n        // +-+-+-+-+-+-+-+-+\r\n        let numSamples;\r\n        let frameSizeOption;\r\n        // Case for CELT-only packet.\r\n        if (this.opusPacketIsCeltOnly(packet)) {\r\n            // The lower 3 'config' bits indicate the frame size option.\r\n            frameSizeOption = (packet.getUint8(0) >> 3) & 0x3;\r\n            // The frame size options 0, 1, 2, 3 correspond to frame sizes of 2.5, 5, 10, 20 ms. Notice that the frame sizes\r\n            // can be represented as (2.5 * 2^0), (2.5 * 2^1), (2.5 * 2^2), (2.5 * 2^3) ms. So, the number of samples can be\r\n            // calculated as follows:\r\n            // (sample/s) * (1s/1000ms) * (2.5ms) * 2^(frameSizeOption)\r\n            // = (sample/s) * (1s/400) * 2^(frameSizeOption)\r\n            // = (sample/s) * 2^(frameSizeOption) * (1s/400)\r\n            numSamples = (sampleRateHz << frameSizeOption) / 400;\r\n        }\r\n        // Case for Hybrid packet. Since Hybrid packets are represented using configurations 12 to 15, bits 1 and 2 in the\r\n        // above TOC byte diagram will both be 1.\r\n        else if ((packet.getUint8(0) & 0x60) === 0x60) {\r\n            // In the case of configuration 13 or 15, bit 4 in the above TOC byte diagram will be 1. Configurations 13 and 15\r\n            // correspond to a 20ms frame size, so the number of samples is calculated as follows:\r\n            // (sample/s) * (1s/1000ms) * (20ms)\r\n            // = (sample/s) * (1s/50)\r\n            //\r\n            // In the case of configuration 12 or 14, bit 4 in the above TOC byte diagram will be 0. Configurations 12 and 14\r\n            // correspond to a 10ms frame size, so the number of samples is calculated as follows:\r\n            // (sample/s) * (1s/1000ms) * (10ms)\r\n            // = (sample/s) * (1s/100)\r\n            numSamples = packet.getUint8(0) & 0x08 ? sampleRateHz / 50 : sampleRateHz / 100;\r\n        }\r\n        // Case for SILK-only packet.\r\n        else {\r\n            // The lower 3 'config' bits indicate the frame size option for SILK-only packets.\r\n            frameSizeOption = (packet.getUint8(0) >> 3) & 0x3;\r\n            if (frameSizeOption === 3) {\r\n                // Frame size option 3 corresponds to a frame size of 60ms, so the number of samples is calculated as follows:\r\n                // (sample/s) * (1s/1000ms) * (60ms)\r\n                // = (sample/s) * (60ms) * (1s/1000ms)\r\n                numSamples = (sampleRateHz * 60) / 1000;\r\n            }\r\n            else {\r\n                // The frame size options 0, 1, 2 correspond to frame sizes of 10, 20, 40 ms. Notice that the frame sizes can be\r\n                // represented as (10 * 2^0), (10 * 2^1), (10 * 2^2) ms. So, the number of samples can be calculated as follows:\r\n                // (sample/s) * (1s/1000ms) * (10ms) * 2^(frameSizeOption)\r\n                // = (sample/s) * (1s/100) * 2^(frameSizeOption)\r\n                // = (sample/s) * 2^(frameSizeOption) * (1s/100)\r\n                numSamples = (sampleRateHz << frameSizeOption) / 100;\r\n            }\r\n        }\r\n        return numSamples;\r\n    }\r\n    /**\r\n     * Gets the number of SILK frames per Opus frame.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @returns Number of SILK frames per Opus frame.\r\n     */\r\n    opusNumSilkFrames(packet) {\r\n        // For computing the frame length in ms, the sample rate is not important since it cancels out. We use 48 kHz, but\r\n        // any valid sample rate would work.\r\n        //\r\n        // To calculate the length of a frame (with a 48kHz sample rate) in ms:\r\n        // (samples/frame) * (1s/48000 samples) * (1000ms/s)\r\n        // = (samples/frame) * (1000ms/48000 samples)\r\n        // = (samples/frame) * (1ms/48 samples)\r\n        let frameLengthMs = this.opusPacketGetSamplesPerFrame(packet, 48000) / 48;\r\n        if (frameLengthMs < 10)\r\n            frameLengthMs = 10;\r\n        // The number of SILK frames per Opus frame is described in https://www.rfc-editor.org/rfc/rfc6716#section-4.2.2.\r\n        switch (frameLengthMs) {\r\n            case 10:\r\n            case 20:\r\n                return 1;\r\n            case 40:\r\n                return 2;\r\n            case 60:\r\n                return 3;\r\n            // It is not possible to reach the default case since an Opus packet can only encode sizes of 2.5, 5, 10, 20, 40,\r\n            // or 60 ms, so we ignore the default case for test coverage.\r\n            /* istanbul ignore next */\r\n            default:\r\n                return 0;\r\n        }\r\n    }\r\n    /**\r\n     * Gets the number of channels from an Opus packet.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @returns Number of channels.\r\n     */\r\n    opusPacketGetNumChannels(packet) {\r\n        // TOC byte format (https://www.rfc-editor.org/rfc/rfc6716#section-3.1):\r\n        //  0\r\n        //  0 1 2 3 4 5 6 7\r\n        // +-+-+-+-+-+-+-+-+\r\n        // | config  |s| c |\r\n        // +-+-+-+-+-+-+-+-+\r\n        // The 's' bit indicates mono or stereo audio, with 0 indicating mono and 1 indicating stereo.\r\n        return packet.getUint8(0) & 0x4 ? 2 : 1;\r\n    }\r\n    /**\r\n     * Determine the size (in bytes) of an Opus frame.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @param byteOffset Offset (from the start of the packet) to the byte containing the size information.\r\n     * @param remainingBytes Remaining number of bytes to parse from the Opus packet.\r\n     * @param sizeBytes Variable to store the parsed frame size (in bytes).\r\n     * @returns Number of bytes that were parsed to determine the frame size.\r\n     */\r\n    opusParseSize(packet, byteOffset, remainingBytes, sizeBytes) {\r\n        // See https://www.rfc-editor.org/rfc/rfc6716#section-3.2.1 for an explanation of how frame size is represented.\r\n        // If there are no remaining bytes to parse the size from, then the size cannot be determined.\r\n        if (remainingBytes < 1) {\r\n            sizeBytes[0] = -1;\r\n            return -1;\r\n        }\r\n        // If the first byte is in the range 0...251, then this value is the size of the frame.\r\n        else if (packet.getUint8(byteOffset) < 252) {\r\n            sizeBytes[0] = packet.getUint8(byteOffset);\r\n            return 1;\r\n        }\r\n        // If the first byte is in the range 252...255, a second byte is needed. If there is no second byte, then the size\r\n        // cannot be determined.\r\n        else if (remainingBytes < 2) {\r\n            sizeBytes[0] = -1;\r\n            return -1;\r\n        }\r\n        // The total size of the frame given two size bytes is:\r\n        // (4 * secondSizeByte) + firstSizeByte\r\n        else {\r\n            sizeBytes[0] = 4 * packet.getUint8(byteOffset + 1) + packet.getUint8(byteOffset);\r\n            return 2;\r\n        }\r\n    }\r\n    /**\r\n     * Parse binary data containing an Opus packet into one or more Opus frames.\r\n     *\r\n     * @param data Binary data containing an Opus packet to be parsed. The data should begin with the first byte (i.e the\r\n     *             TOC byte) of an Opus packet. Note that the size of the data does not have to equal the size of the\r\n     *             contained Opus packet.\r\n     * @param lenBytes Size of the data (in bytes).\r\n     * @param selfDelimited Indicates if the Opus packet is self-delimiting\r\n     *                      (https://www.rfc-editor.org/rfc/rfc6716#appendix-B).\r\n     * @param tocByte Optional variable to store the TOC (table of contents) byte.\r\n     * @param frameOffsets Optional variable to store the offsets (from the start of the data) to the first bytes of each\r\n     *                     Opus frame.\r\n     * @param frameSizes Required variable to store the sizes (in bytes) of each Opus frame.\r\n     * @param payloadOffset Optional variable to store the offset (from the start of the data) to the first byte of the\r\n     *                      payload.\r\n     * @param packetLenBytes Optional variable to store the length of the Opus packet (in bytes).\r\n     * @returns Number of Opus frames.\r\n     */\r\n    opusPacketParseImpl(data, lenBytes, selfDelimited, tocByte, frameOffsets, frameSizes, payloadOffset, packetLenBytes) {\r\n        if (!frameSizes || lenBytes < 0)\r\n            return this.OPUS_BAD_ARG;\r\n        if (lenBytes === 0)\r\n            return this.OPUS_INVALID_PACKET;\r\n        // The number of Opus frames in the packet.\r\n        let numFrames;\r\n        // Intermediate storage for the number of bytes parsed to determine the size of a frame.\r\n        let numBytesParsed;\r\n        // The number of the padding bytes (excluding the padding count bytes) in the packet.\r\n        let paddingBytes = 0;\r\n        // Indicates whether CBR (constant bitrate) framing is used.\r\n        let cbr = false;\r\n        // The TOC (table of contents) byte (https://www.rfc-editor.org/rfc/rfc6716#section-3.1).\r\n        const toc = data.getUint8(0);\r\n        // Store the TOC byte.\r\n        if (tocByte)\r\n            tocByte[0] = toc;\r\n        // The remaining number of bytes to parse from the packet. Note that the TOC byte has already been parsed, hence the\r\n        // minus 1.\r\n        let remainingBytes = lenBytes - 1;\r\n        // This keeps track of where we are in the packet. This starts at 1 since the TOC byte has already been read.\r\n        let byteOffset = 1;\r\n        // The size of the last Opus frame in bytes.\r\n        let lastSizeBytes = remainingBytes;\r\n        // Read the `c` bits (i.e. code bits) from the TOC byte.\r\n        switch (toc & 0x3) {\r\n            // A code 0 packet (https://www.rfc-editor.org/rfc/rfc6716#section-3.2.2) has one frame.\r\n            case 0:\r\n                numFrames = 1;\r\n                break;\r\n            // A code 1 packet (https://www.rfc-editor.org/rfc/rfc6716#section-3.2.3) has two CBR (constant bitrate) frames.\r\n            case 1:\r\n                numFrames = 2;\r\n                cbr = true;\r\n                if (!selfDelimited) {\r\n                    // Undelimited code 1 packets must be an even number of data bytes, otherwise the packet is invalid.\r\n                    if (remainingBytes & 0x1)\r\n                        return this.OPUS_INVALID_PACKET;\r\n                    // The sizes of both frames are equal (i.e. half of the number of data bytes).\r\n                    lastSizeBytes = remainingBytes / 2;\r\n                    // If `lastSizeBytes` is too large, we will catch it later.\r\n                    frameSizes[0][0] = lastSizeBytes;\r\n                }\r\n                break;\r\n            // A code 2 packet (https://www.rfc-editor.org/rfc/rfc6716#section-3.2.4) has two VBR (variable bitrate) frames.\r\n            case 2:\r\n                numFrames = 2;\r\n                numBytesParsed = this.opusParseSize(data, byteOffset, remainingBytes, frameSizes[0]);\r\n                remainingBytes -= numBytesParsed;\r\n                // The parsed size of the first frame cannot be larger than the number of remaining bytes in the packet.\r\n                if (frameSizes[0][0] < 0 || frameSizes[0][0] > remainingBytes) {\r\n                    return this.OPUS_INVALID_PACKET;\r\n                }\r\n                byteOffset += numBytesParsed;\r\n                // The size of the second frame is the remaining number of bytes after the first frame.\r\n                lastSizeBytes = remainingBytes - frameSizes[0][0];\r\n                break;\r\n            // A code 3 packet (https://www.rfc-editor.org/rfc/rfc6716#section-3.2.5) has multiple CBR/VBR frames (from 0 to\r\n            // 120 ms).\r\n            default:\r\n                // Code 3 packets must have at least 2 bytes (i.e. at least 1 byte after the TOC byte).\r\n                if (remainingBytes < 1)\r\n                    return this.OPUS_INVALID_PACKET;\r\n                // Frame count byte format:\r\n                //  0\r\n                //  0 1 2 3 4 5 6 7\r\n                // +-+-+-+-+-+-+-+-+\r\n                // |v|p|     M     |\r\n                // +-+-+-+-+-+-+-+-+\r\n                //\r\n                // Read the frame count byte, which immediately follows the TOC byte.\r\n                const frameCountByte = data.getUint8(byteOffset++);\r\n                --remainingBytes;\r\n                // Read the 'M' bits of the frame count byte, which encode the number of frames.\r\n                numFrames = frameCountByte & 0x3f;\r\n                // The number of frames in a code 3 packet must not be 0.\r\n                if (numFrames <= 0)\r\n                    return this.OPUS_INVALID_PACKET;\r\n                const samplesPerFrame = this.opusPacketGetSamplesPerFrame(data, 48000);\r\n                // A single frame can have at most 2880 samples, which happens in the case where 60ms of 48kHz audio is encoded\r\n                // per frame. A code 3 packet cannot contain more than 120ms of audio, so the total number of samples cannot\r\n                // exceed 2880 * 2 = 5760.\r\n                if (samplesPerFrame * numFrames > 5760)\r\n                    return this.OPUS_INVALID_PACKET;\r\n                // Parse padding bytes if the 'p' bit is 1.\r\n                if (frameCountByte & 0x40) {\r\n                    let paddingCountByte;\r\n                    let numPaddingBytes;\r\n                    // Remove padding bytes (including padding count bytes) from the remaining byte count.\r\n                    do {\r\n                        // Sanity check that there are enough bytes to parse and remove the padding.\r\n                        if (remainingBytes <= 0)\r\n                            return this.OPUS_INVALID_PACKET;\r\n                        // Get the next padding count byte.\r\n                        paddingCountByte = data.getUint8(byteOffset++);\r\n                        --remainingBytes;\r\n                        // If the padding count byte has a value in the range 0...254, then the total size of the padding is the\r\n                        // value in the padding count byte.\r\n                        //\r\n                        // If the padding count byte has value 255, then the total size of the padding is 254 plus the value in the\r\n                        // next padding count byte. Therefore, keep reading padding count bytes while the value is 255.\r\n                        numPaddingBytes = paddingCountByte === 255 ? 254 : paddingCountByte;\r\n                        remainingBytes -= numPaddingBytes;\r\n                        paddingBytes += numPaddingBytes;\r\n                    } while (paddingCountByte === 255);\r\n                }\r\n                // Sanity check that the remaining number of bytes is not negative after removing the padding.\r\n                if (remainingBytes < 0)\r\n                    return this.OPUS_INVALID_PACKET;\r\n                // Read the 'v' bit (i.e. VBR bit).\r\n                cbr = !(frameCountByte & 0x80);\r\n                // VBR case\r\n                if (!cbr) {\r\n                    lastSizeBytes = remainingBytes;\r\n                    // Let M be the number of frames. There will be M - 1 frame length indicators (which can be 1 or 2 bytes)\r\n                    // corresponding to the lengths of frames 0 to M - 2. The size of the last frame (i.e. frame M - 1) is the\r\n                    // number of data bytes after the end of frame M - 2 and before the start of the padding bytes.\r\n                    for (let i = 0; i < numFrames - 1; ++i) {\r\n                        numBytesParsed = this.opusParseSize(data, byteOffset, remainingBytes, frameSizes[i]);\r\n                        remainingBytes -= numBytesParsed;\r\n                        // The remaining number of data bytes must be enough to contain each frame.\r\n                        if (frameSizes[i][0] < 0 || frameSizes[i][0] > remainingBytes) {\r\n                            return this.OPUS_INVALID_PACKET;\r\n                        }\r\n                        byteOffset += numBytesParsed;\r\n                        lastSizeBytes -= numBytesParsed + frameSizes[i][0];\r\n                    }\r\n                    // Sanity check that the size of the last frame is not negative.\r\n                    if (lastSizeBytes < 0)\r\n                        return this.OPUS_INVALID_PACKET;\r\n                }\r\n                // CBR case\r\n                else if (!selfDelimited) {\r\n                    // The size of each frame is the number of data bytes divided by the number of frames.\r\n                    lastSizeBytes = Math.trunc(remainingBytes / numFrames);\r\n                    // The number of data bytes must be a non-negative integer multiple of the number of frames.\r\n                    if (lastSizeBytes * numFrames !== remainingBytes)\r\n                        return this.OPUS_INVALID_PACKET;\r\n                    // All frames have equal size in the undelimited CBR case.\r\n                    for (let i = 0; i < numFrames - 1; ++i) {\r\n                        frameSizes[i][0] = lastSizeBytes;\r\n                    }\r\n                }\r\n        }\r\n        // Self-delimited framing uses an extra 1 or 2 bytes, immediately preceding the data bytes, to indicate either the\r\n        // size of the last frame (for code 0, code 2, and VBR code 3 packets) or the size of all the frames (for code 1 and\r\n        // CBR code 3 packets). See https://www.rfc-editor.org/rfc/rfc6716#appendix-B.\r\n        if (selfDelimited) {\r\n            // The extra frame size byte(s) will always indicate the size of the last frame.\r\n            numBytesParsed = this.opusParseSize(data, byteOffset, remainingBytes, frameSizes[numFrames - 1]);\r\n            remainingBytes -= numBytesParsed;\r\n            // There must be enough data bytes for the last frame.\r\n            if (frameSizes[numFrames - 1][0] < 0 || frameSizes[numFrames - 1][0] > remainingBytes) {\r\n                return this.OPUS_INVALID_PACKET;\r\n            }\r\n            byteOffset += numBytesParsed;\r\n            // For CBR packets, the sizes of all the frames are equal.\r\n            if (cbr) {\r\n                // There must be enough data bytes for all the frames.\r\n                if (frameSizes[numFrames - 1][0] * numFrames > remainingBytes) {\r\n                    return this.OPUS_INVALID_PACKET;\r\n                }\r\n                for (let i = 0; i < numFrames - 1; ++i) {\r\n                    frameSizes[i][0] = frameSizes[numFrames - 1][0];\r\n                }\r\n            }\r\n            // At this point, `lastSizeBytes` contains the size of the last frame plus the size of the extra frame size\r\n            // byte(s), so sanity check that `lastSizeBytes` is the upper bound for the size of the last frame.\r\n            else if (!(numBytesParsed + frameSizes[numFrames - 1][0] <= lastSizeBytes)) {\r\n                return this.OPUS_INVALID_PACKET;\r\n            }\r\n        }\r\n        // Undelimited case\r\n        else {\r\n            // Because the size of the last packet is not encoded explicitly, it is possible that the size of the last packet\r\n            // (or of all the packets, for the CBR case) is larger than maximum frame size.\r\n            if (lastSizeBytes > this.OPUS_MAX_FRAME_SIZE_BYTES)\r\n                return this.OPUS_INVALID_PACKET;\r\n            frameSizes[numFrames - 1][0] = lastSizeBytes;\r\n        }\r\n        // Store the offset to the start of the payload.\r\n        if (payloadOffset)\r\n            payloadOffset[0] = byteOffset;\r\n        // Store the offsets to the start of each frame.\r\n        for (let i = 0; i < numFrames; ++i) {\r\n            if (frameOffsets)\r\n                frameOffsets[i][0] = byteOffset;\r\n            byteOffset += frameSizes[i][0];\r\n        }\r\n        // Store the length of the Opus packet.\r\n        if (packetLenBytes)\r\n            packetLenBytes[0] = byteOffset + paddingBytes;\r\n        return numFrames;\r\n    }\r\n    /**\r\n     * Parse a single undelimited Opus packet into one or more Opus frames.\r\n     *\r\n     * @param packet Opus packet to be parsed.\r\n     * @param lenBytes Size of the packet (in bytes).\r\n     * @param tocByte Optional variable to store the TOC (table of contents) byte.\r\n     * @param frameOffsets Optional variable to store the offsets (from the start of the packet) to the first bytes of\r\n     *                     each Opus frame.\r\n     * @param frameSizes Required variable to store the sizes (in bytes) of each Opus frame.\r\n     * @param payloadOffset Optional variable to store the offset (from the start of the packet) to the first byte of the\r\n     *                      payload.\r\n     * @returns Number of Opus frames.\r\n     */\r\n    opusPacketParse(packet, lenBytes, tocByte, frameOffsets, frameSizes, payloadOffset) {\r\n        return this.opusPacketParseImpl(packet, lenBytes, \r\n        /* selfDelimited */ false, tocByte, frameOffsets, frameSizes, payloadOffset, null);\r\n    }\r\n    /**\r\n     * This function returns the SILK VAD (voice activity detection) information encoded in the Opus packet. For CELT-only\r\n     * packets that do not have VAD information, it returns -1.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @param lenBytes Size of the packet (in bytes).\r\n     * @returns  0: no frame had the VAD flag set.\r\n     *           1: at least one frame had the VAD flag set.\r\n     *          -1: VAD status could not be determined.\r\n     */\r\n    opusPacketHasVoiceActivity(packet, lenBytes) {\r\n        if (!packet || lenBytes <= 0)\r\n            return 0;\r\n        // In CELT-only mode, we can not determine whether there is VAD.\r\n        if (this.opusPacketIsCeltOnly(packet))\r\n            return -1;\r\n        const numSilkFrames = this.opusNumSilkFrames(packet);\r\n        // It is not possible for `opusNumSilkFrames()` to return 0, so we ignore the next sanity check for test coverage.\r\n        /* istanbul ignore next */\r\n        if (numSilkFrames === 0)\r\n            return -1;\r\n        const opusFrameOffsets = new Array(this.OPUS_MAX_OPUS_FRAMES);\r\n        const opusFrameSizes = new Array(this.OPUS_MAX_OPUS_FRAMES);\r\n        for (let i = 0; i < this.OPUS_MAX_OPUS_FRAMES; ++i) {\r\n            opusFrameOffsets[i] = [undefined];\r\n            opusFrameSizes[i] = [undefined];\r\n        }\r\n        // Parse packet to get the Opus frames.\r\n        const numOpusFrames = this.opusPacketParse(packet, lenBytes, null, opusFrameOffsets, opusFrameSizes, null);\r\n        // VAD status cannot be determined for invalid packets.\r\n        if (numOpusFrames < 0)\r\n            return -1;\r\n        // Iterate over all Opus frames, which may contain multiple SILK frames, to determine the VAD status.\r\n        for (let i = 0; i < numOpusFrames; ++i) {\r\n            if (opusFrameSizes[i][0] < 1)\r\n                continue;\r\n            // LP layer header bits format (https://www.rfc-editor.org/rfc/rfc6716#section-4.2.3):\r\n            //\r\n            // Mono case:\r\n            // +-----------------+----------+\r\n            // | 1 to 3 VAD bits | LBRR bit |\r\n            // +-----------------+----------+\r\n            //\r\n            // Stereo case:\r\n            // +---------------------+--------------+----------------------+---------------+\r\n            // | 1 to 3 mid VAD bits | mid LBRR bit | 1 to 3 side VAD bits | side LBRR bit |\r\n            // +---------------------+--------------+----------------------+---------------+\r\n            // The upper 1 to 3 bits (dependent on the number of SILK frames) of the LP layer contain VAD bits. If any of\r\n            // these VAD bits are 1, then voice activity is present.\r\n            if (packet.getUint8(opusFrameOffsets[i][0]) >> (8 - numSilkFrames))\r\n                return 1;\r\n            // In the stereo case, there is a second set of 1 to 3 VAD bits, so also check these VAD bits.\r\n            const channels = this.opusPacketGetNumChannels(packet);\r\n            if (channels === 2 &&\r\n                (packet.getUint8(opusFrameOffsets[i][0]) << (numSilkFrames + 1)) >> (8 - numSilkFrames)) {\r\n                return 1;\r\n            }\r\n        }\r\n        // No voice activity was detected.\r\n        return 0;\r\n    }\r\n    /**\r\n     * This method is based on Definition of the Opus Audio Codec\r\n     * (https://tools.ietf.org/html/rfc6716). Basically, this method is based on\r\n     * parsing the LP layer of an Opus packet, particularly the LBRR flag.\r\n     *\r\n     * @param packet Opus packet.\r\n     * @param lenBytes Size of the packet (in bytes).\r\n     * @returns  true: packet has fec encoding about previous packet.\r\n     *           false: no fec encoding present.\r\n     */\r\n    opusPacketHasFec(packet, lenBytes) {\r\n        if (!packet || lenBytes <= 0)\r\n            return false;\r\n        // In CELT-only mode, packets should not have FEC.\r\n        if (this.opusPacketIsCeltOnly(packet))\r\n            return false;\r\n        const opusFrameOffsets = new Array(this.OPUS_MAX_OPUS_FRAMES);\r\n        const opusFrameSizes = new Array(this.OPUS_MAX_OPUS_FRAMES);\r\n        for (let i = 0; i < this.OPUS_MAX_OPUS_FRAMES; ++i) {\r\n            opusFrameOffsets[i] = [undefined];\r\n            opusFrameSizes[i] = [undefined];\r\n        }\r\n        // Parse packet to get the Opus frames.\r\n        const numOpusFrames = this.opusPacketParse(packet, lenBytes, null, opusFrameOffsets, opusFrameSizes, null);\r\n        if (numOpusFrames < 0)\r\n            return false;\r\n        /* istanbul ignore next */\r\n        if (opusFrameSizes[0][0] <= 1)\r\n            return false;\r\n        const numSilkFrames = this.opusNumSilkFrames(packet);\r\n        /* istanbul ignore next */\r\n        if (numSilkFrames === 0)\r\n            return false;\r\n        const channels = this.opusPacketGetNumChannels(packet);\r\n        /* istanbul ignore next */\r\n        if (channels !== 1 && channels !== 2)\r\n            return false;\r\n        // A frame starts with the LP layer. The LP layer begins with two to eight\r\n        // header bits.These consist of one VAD bit per SILK frame (up to 3),\r\n        // followed by a single flag indicating the presence of LBRR frames.\r\n        // For a stereo packet, these first flags correspond to the mid channel, and\r\n        // a second set of flags is included for the side channel. Because these are\r\n        // the first symbols decoded by the range coder and because they are coded\r\n        // as binary values with uniform probability, they can be extracted directly\r\n        // from the most significant bits of the first byte of compressed data.\r\n        for (let i = 0; i < channels; i++) {\r\n            if (packet.getUint8(opusFrameOffsets[0][0]) & (0x80 >> ((i + 1) * (numSilkFrames + 1) - 1)))\r\n                return true;\r\n        }\r\n        return false;\r\n    }\r\n}\nRedundantAudioEncoder.shouldLog = true;\nRedundantAudioEncoder.shouldReportStats = true;\nRedundantAudioEncoder.initializeWorker();\n";

export default RedundantAudioEncoderWorkerCode;
